spring:
  application:
    name: langgraph-poc
  main:
    allow-bean-definition-overriding: true
  ai:
    openai:
      api-key: ${OPENAI_API_KEY}
      base-url: ${OPENAI_API_BASE_URL:/v1}
      chat:
        options:
          model: ${MODEL_NAME}
          temperature: ${TEMPERATURE:0.1}
          max-tokens: ${MAX_TOKENS:512}
    # Uncomment below to use local Ollama instead of OpenAI
    # ollama:
    #   base-url: http://localhost:11434
    #   chat:
    #     options:
    #       model: qwen2.5:7b
    #       temperature: 0.0

server:
  port: 8080

logging:
  level:
    com.datanova: DEBUG
    org.bsc.langgraph4j: DEBUG
